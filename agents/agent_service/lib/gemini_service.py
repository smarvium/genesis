import os
import time
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
import httpx
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Get API key from environment
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Gemini API endpoints
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models"
GEMINI_PRO_MODEL = "gemini-pro"
GEMINI_PRO_VISION_MODEL = "gemini-pro-vision"
GEMINI_FLASH_MODEL = "gemini-flash"

class GeminiService:
    """Service for interacting with Google's Gemini AI models."""
    
    def __init__(self, api_key: Optional[str] = None, model: str = GEMINI_PRO_MODEL):
        """Initialize the Gemini service with API key and default model.
        
        Args:
            api_key: The Gemini API key. If None, will use environment variable.
            model: The Gemini model to use. Defaults to gemini-pro.
        """
        self.api_key = api_key or GEMINI_API_KEY
        self.model = model
        self.client = httpx.AsyncClient(timeout=60.0)  # Increased timeout for larger responses
        
        if not self.api_key or self.api_key.startswith("your_"):
            logger.warning("âš ï¸ No valid Gemini API key found. Using mock responses.")
            self.use_mock = True
        else:
            self.use_mock = False
            logger.info(f"ðŸ§  Gemini service initialized with model: {model}")

    async def generate_content(
        self, 
        prompt: str, 
        system_instruction: Optional[str] = None,
        temperature: float = 0.7, 
        max_tokens: int = 1024,
        top_p: float = 0.95,
        top_k: int = 40
    ) -> Tuple[str, str]:
        """Generate text content using Gemini model.
        
        Args:
            prompt: The text prompt to send to the model.
            system_instruction: Optional system instruction to guide the model.
            temperature: Controls randomness. Lower values make output more deterministic.
            max_tokens: Maximum number of tokens to generate.
            top_p: Nucleus sampling parameter.
            top_k: Top-k sampling parameter.
            
        Returns:
            Tuple of (generated_text, chain_of_thought)
        """
        if self.use_mock:
            return self._generate_mock_response(prompt, system_instruction)
        
        try:
            url = f"{GEMINI_API_URL}/{self.model}:generateContent?key={self.api_key}"
            
            # Construct request body
            request_body = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": temperature,
                    "maxOutputTokens": max_tokens,
                    "topP": top_p,
                    "topK": top_k
                },
                "safetySettings": [
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    }
                ]
            }
            
            # Add system instruction if provided
            if system_instruction:
                request_body["systemInstruction"] = {"parts": [{"text": system_instruction}]}
            
            # Make API request
            start_time = time.time()
            response = await self.client.post(
                url,
                json=request_body
            )
            response_time = time.time() - start_time
            
            if response.status_code != 200:
                logger.error(f"âŒ Gemini API error: {response.status_code} {response.text}")
                return (
                    f"I encountered an error while processing your request. Please try again later.",
                    f"API Error: {response.status_code} - {response.text[:500]}"
                )
            
            # Parse response
            response_data = response.json()
            
            # Extract the generated text
            output_text = ""
            chain_of_thought = f"API Response Time: {response_time:.2f}s\n"
            
            if "candidates" in response_data and response_data["candidates"]:
                candidate = response_data["candidates"][0]
                
                if "content" in candidate and "parts" in candidate["content"]:
                    for part in candidate["content"]["parts"]:
                        if "text" in part:
                            output_text += part["text"]
                
                # Extract chain of thought if available
                if "citationMetadata" in candidate:
                    chain_of_thought += "Citations:\n"
                    for citation in candidate["citationMetadata"].get("citations", []):
                        chain_of_thought += f"- {citation.get('title', 'Unknown source')}\n"
                
                if "safetyRatings" in candidate:
                    chain_of_thought += "\nSafety Ratings:\n"
                    for rating in candidate["safetyRatings"]:
                        chain_of_thought += f"- {rating.get('category', 'Unknown')}: {rating.get('probability', 'UNKNOWN')}\n"
                
                # If finishReason is present, add it to chain of thought
                if "finishReason" in candidate:
                    chain_of_thought += f"\nFinish Reason: {candidate['finishReason']}\n"
                
                # Add model details
                chain_of_thought += f"\nModel: {self.model}\n"
                chain_of_thought += f"Temperature: {temperature}\n"
                chain_of_thought += f"Max Tokens: {max_tokens}\n"
            else:
                logger.warning("âš ï¸ Unexpected Gemini API response format")
                output_text = "I'm sorry, I encountered an issue processing your request."
                chain_of_thought = f"Unexpected API response format: {str(response_data)[:500]}"
            
            logger.info(f"âœ… Gemini response generated in {response_time:.2f}s")
            return output_text, chain_of_thought
            
        except Exception as e:
            logger.error(f"âŒ Error calling Gemini API: {str(e)}")
            return (
                f"I encountered an error while processing your request. Please try again later.",
                f"Exception: {str(e)}"
            )
    
    async def generate_blueprint(self, user_input: str) -> Dict[str, Any]:
        """Generate a GenesisOS blueprint from user input.
        
        Args:
            user_input: The user's description of what they want to build.
            
        Returns:
            A blueprint dictionary with guild structure.
        """
        if self.use_mock:
            return self._generate_mock_blueprint(user_input)
        
        try:
            # System instruction specific to blueprint generation
            system_instruction = """
            You are GenesisOS Blueprint Generator, an expert AI system architect specialized in designing 
            AI agent-based systems. Your role is to analyze user goals and create 
            structured blueprints for autonomous digital workforces.
            
            Your output must follow this exact JSON structure:
            {
                "id": "blueprint-[unique_id]",
                "user_input": "[original user input]",
                "interpretation": "[your understanding of the user's goal]",
                "suggested_structure": {
                    "guild_name": "[appropriate name for this guild]",
                    "guild_purpose": "[clear purpose statement]",
                    "agents": [
                        {
                            "name": "[agent name]",
                            "role": "[specific role]",
                            "description": "[detailed description]",
                            "tools_needed": ["[tool1]", "[tool2]", "..."]
                        }
                    ],
                    "workflows": [
                        {
                            "name": "[workflow name]",
                            "description": "[detailed description]",
                            "trigger_type": "[manual|schedule|webhook|event]"
                        }
                    ]
                }
            }
            
            Create coherent, business-focused blueprints with:
            - 2-5 specialized agents with distinct roles
            - 1-3 well-defined workflows
            - Appropriate tools for each agent
            - Realistic integrations (Slack, Email, Google Sheets, etc.)
            """
            
            # Design the prompt for Gemini
            prompt = f"""
            Create a complete blueprint for an AI-powered digital workforce based on this user goal:
            
            "{user_input}"
            
            Design a system of intelligent AI agents working together to achieve this goal.
            Include specialized agents with clear roles, appropriate tools, and workflow automations.
            """
            
            # Get response from Gemini
            output_text, chain_of_thought = await self.generate_content(
                prompt=prompt,
                system_instruction=system_instruction,
                temperature=0.7,
                max_tokens=2048
            )
            
            # Extract JSON from response
            try:
                # Look for JSON structure in the response
                json_start = output_text.find('{')
                json_end = output_text.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = output_text[json_start:json_end]
                    blueprint = json.loads(json_str)
                    
                    # Validate the blueprint has the required structure
                    if not self._validate_blueprint(blueprint):
                        logger.warning("âš ï¸ Generated blueprint is missing required fields")
                        blueprint = self._generate_mock_blueprint(user_input)
                    
                    logger.info(f"âœ… Blueprint generated successfully with {len(blueprint['suggested_structure']['agents'])} agents")
                    return blueprint
                else:
                    logger.warning("âš ï¸ No valid JSON found in Gemini response")
                    return self._generate_mock_blueprint(user_input)
            except json.JSONDecodeError:
                logger.error(f"âŒ Failed to parse JSON from Gemini response: {output_text[:200]}...")
                return self._generate_mock_blueprint(user_input)
        except Exception as e:
            logger.error(f"âŒ Blueprint generation error: {str(e)}")
            return self._generate_mock_blueprint(user_input)
    
    def _validate_blueprint(self, blueprint: Dict[str, Any]) -> bool:
        """Validate that blueprint has all required fields.
        
        Args:
            blueprint: The blueprint to validate.
            
        Returns:
            True if valid, False otherwise.
        """
        # Check top-level keys
        required_keys = ["id", "user_input", "interpretation", "suggested_structure"]
        if not all(key in blueprint for key in required_keys):
            return False
        
        # Check suggested_structure
        structure = blueprint.get("suggested_structure", {})
        structure_keys = ["guild_name", "guild_purpose", "agents", "workflows"]
        if not all(key in structure for key in structure_keys):
            return False
        
        # Check agents
        agents = structure.get("agents", [])
        if not isinstance(agents, list) or len(agents) == 0:
            return False
        
        for agent in agents:
            agent_keys = ["name", "role", "description", "tools_needed"]
            if not all(key in agent for key in agent_keys):
                return False
        
        # Check workflows
        workflows = structure.get("workflows", [])
        if not isinstance(workflows, list) or len(workflows) == 0:
            return False
        
        for workflow in workflows:
            workflow_keys = ["name", "description", "trigger_type"]
            if not all(key in workflow for key in workflow_keys):
                return False
        
        return True
    
    def _generate_mock_blueprint(self, user_input: str) -> Dict[str, Any]:
        """Generate a mock blueprint when Gemini API is not available.
        
        Args:
            user_input: The user's description of what they want to build.
            
        Returns:
            A blueprint dictionary with guild structure.
        """
        logger.info("ðŸ”„ Generating mock blueprint as fallback")
        
        # Generate a guild name based on user input
        keywords = user_input.lower()
        if "customer" in keywords or "support" in keywords:
            guild_name = "Customer Success Intelligence Guild"
            purpose = "Automate and enhance customer support operations"
            agents = [
                {
                    "name": "Support Specialist",
                    "role": "Customer Support Lead",
                    "description": "Handles customer inquiries and resolves issues efficiently",
                    "tools_needed": ["Zendesk API", "Email API", "Knowledge Base"]
                },
                {
                    "name": "Analytics Expert",
                    "role": "Support Data Analyst",
                    "description": "Analyzes customer support data to identify trends and improvements",
                    "tools_needed": ["Google Analytics", "Database", "Reporting Tools"]
                }
            ]
            workflows = [
                {
                    "name": "Ticket Resolution Workflow",
                    "description": "Automatically processes and resolves customer support tickets",
                    "trigger_type": "webhook"
                }
            ]
        elif "sales" in keywords or "revenue" in keywords:
            guild_name = "Revenue Growth Guild"
            purpose = "Boost sales and optimize revenue generation"
            agents = [
                {
                    "name": "Sales Specialist",
                    "role": "Lead Generation Expert",
                    "description": "Identifies and qualifies sales leads for follow-up",
                    "tools_needed": ["CRM API", "LinkedIn API", "Email API"]
                },
                {
                    "name": "Revenue Analyst",
                    "role": "Sales Performance Analyst",
                    "description": "Analyzes sales data and recommends optimization strategies",
                    "tools_needed": ["Spreadsheet", "Data Visualization", "CRM API"]
                }
            ]
            workflows = [
                {
                    "name": "Lead Nurturing Sequence",
                    "description": "Automatically nurtures leads through email sequences",
                    "trigger_type": "schedule"
                }
            ]
        elif "marketing" in keywords or "content" in keywords:
            guild_name = "Marketing Intelligence Guild"
            purpose = "Drive marketing campaigns and content creation"
            agents = [
                {
                    "name": "Content Creator",
                    "role": "Content Marketing Specialist",
                    "description": "Generates and publishes marketing content across channels",
                    "tools_needed": ["CMS API", "SEO Tools", "Social Media API"]
                },
                {
                    "name": "Campaign Manager",
                    "role": "Marketing Campaign Orchestrator",
                    "description": "Plans and executes marketing campaigns and tracks results",
                    "tools_needed": ["Analytics API", "Email Marketing", "Ad Platform API"]
                }
            ]
            workflows = [
                {
                    "name": "Content Calendar Automation",
                    "description": "Manages content publishing schedule across platforms",
                    "trigger_type": "schedule"
                }
            ]
        else:
            guild_name = "Business Automation Guild"
            purpose = "Automate core business processes and operations"
            agents = [
                {
                    "name": "Operations Manager",
                    "role": "Process Automation Specialist",
                    "description": "Oversees business process automation and optimization",
                    "tools_needed": ["Database", "API Integration", "Workflow Engine"]
                },
                {
                    "name": "Business Analyst",
                    "role": "Data Analysis Expert",
                    "description": "Analyzes business metrics and provides actionable insights",
                    "tools_needed": ["Analytics Tools", "Data Visualization", "Database"]
                }
            ]
            workflows = [
                {
                    "name": "Business Metrics Report",
                    "description": "Automatically generates and distributes business performance reports",
                    "trigger_type": "schedule"
                }
            ]
        
        # Create a unique blueprint ID
        blueprint_id = f"blueprint-{int(time.time())}"
        
        # Create the blueprint structure
        blueprint = {
            "id": blueprint_id,
            "user_input": user_input,
            "interpretation": f"I understand you want to {user_input}. I've created a blueprint to help you achieve this through an intelligent AI guild.",
            "suggested_structure": {
                "guild_name": guild_name,
                "guild_purpose": purpose,
                "agents": agents,
                "workflows": workflows
            }
        }
        
        return blueprint
    
    def _generate_mock_response(self, prompt: str, system_instruction: Optional[str] = None) -> Tuple[str, str]:
        """Generate a mock response when Gemini API is not available.
        
        Args:
            prompt: The text prompt.
            system_instruction: Optional system instruction.
            
        Returns:
            Tuple of (mock_response, chain_of_thought)
        """
        # Simple keyword-based mock responses
        prompt_lower = prompt.lower()
        
        if "hello" in prompt_lower or "hi " in prompt_lower:
            response = "Hello! I'm your AI assistant. How can I help you today?"
            chain_of_thought = "Identified greeting, responding with a friendly welcome message."
        elif "blueprint" in prompt_lower:
            response = "I can help you create a blueprint for your business automation needs. Would you like me to analyze your requirements and suggest an AI agent structure?"
            chain_of_thought = "Detected blueprint-related query. Offering to create a GenesisOS blueprint."
        elif "agent" in prompt_lower:
            response = "AI agents can handle specialized tasks in your business. They can be configured with different roles, tools, and capabilities to automate workflows."
            chain_of_thought = "Query about agents. Providing general information about AI agent capabilities."
        elif "workflow" in prompt_lower:
            response = "Workflows connect your AI agents to accomplish complex business processes. They can be triggered manually, on a schedule, or by external events."
            chain_of_thought = "Query about workflows. Explaining how workflows function within GenesisOS."
        else:
            # Generic response for other queries
            response = f"I've analyzed your request about '{prompt}'. To help you better, could you provide more details about your specific business needs or goals?"
            chain_of_thought = "General query received. Requesting more specific information to provide a tailored response."
        
        if system_instruction:
            chain_of_thought = f"System instruction: {system_instruction[:100]}...\n" + chain_of_thought
        
        chain_of_thought += "\nNOTE: This is a mock response generated without using the Gemini API."
        
        return response, chain_of_thought
    
    async def close(self):
        """Close the HTTP client."""
        await self.client.aclose()


# Create a singleton instance for the service
_gemini_service = None

def get_gemini_service(api_key: Optional[str] = None, model: str = GEMINI_PRO_MODEL) -> GeminiService:
    """Get the singleton GeminiService instance.
    
    Args:
        api_key: Optional API key override.
        model: Optional model override.
        
    Returns:
        GeminiService instance.
    """
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiService(api_key, model)
    return _gemini_service